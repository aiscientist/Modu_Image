{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLearn 관련 URL 모음\n",
    "\n",
    "https://github.com/tflearn/tflearn/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-994095198065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'biases'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_bias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#In Tensorflow, writing these kinds of operations can be quite tedious:\n",
    "\n",
    "with tf.name_scope('conv1'):\n",
    "    W = tf.Variable(tf.random_normal([5, 5, 1, 32]), dtype=tf.float32, name='Weights')\n",
    "    b = tf.Variable(tf.random_normal([32]), dtype=tf.float32, name='biases')\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    x = tf.add_bias(W, b)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "#Simple Layer\n",
    "tflearn.conv_2d(x, 32, 5, activation='relu', name='conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Exmaples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.15389\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1000 | loss: 0.15389 - R2: 0.9917 -- iter: 17/17\n",
      "\n",
      "Regression result:\n",
      "Y = [ 0.24944803].X + [ 0.81430537]\n",
      "\n",
      "Test prediction for y = 3.2 and y = 4.5:\n",
      "[1.6125390529632568, 1.936821460723877]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Linear Regression Example \"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tflearn\n",
    "\n",
    "# Regression data\n",
    "X = [3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,7.042,10.791,5.313,7.997,5.654,9.27,3.1]\n",
    "Y = [1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,2.827,3.465,1.65,2.904,2.42,2.94,1.3]\n",
    "\n",
    "# Linear Regression graph\n",
    "input_ = tflearn.input_data(shape=[None])\n",
    "linear = tflearn.single_unit(input_)\n",
    "regression = tflearn.regression(linear, optimizer='sgd', loss='mean_square',\n",
    "                                metric='R2', learning_rate=0.01)\n",
    "m = tflearn.DNN(regression)\n",
    "m.fit(X, Y, n_epoch=1000, show_metric=True, snapshot_epoch=False)\n",
    "\n",
    "print(\"\\nRegression result:\")\n",
    "print(\"Y = \" + str(m.get_weights(linear.W)) +\n",
    "      \".X + \" + str(m.get_weights(linear.b)))\n",
    "\n",
    "print(\"\\nTest prediction for y = 3.2 and y = 4.5:\")\n",
    "print(m.predict([3.2, 4.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.81750\u001b[0m\u001b[0m\n",
      "| SGD_0 | epoch: 400 | loss: 0.40855 -- iter: 4/4\n",
      "| SGD_1 | epoch: 400 | loss: 0.40895 -- iter: 4/4\n",
      "Testing XOR operator\n",
      "0 xor 0: [[0.0005646706558763981]]\n",
      "0 xor 1: [[0.998274564743042]]\n",
      "1 xor 0: [[0.9982590079307556]]\n",
      "1 xor 1: [[0.0009251838782802224]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Simple Example to train logical operators\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "# Logical NOT operator\n",
    "X = [[0.], [1.]]\n",
    "Y = [[1.], [0.]]\n",
    "\n",
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    g = tflearn.input_data(shape=[None, 1])\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 1, activation='sigmoid')\n",
    "    g = tflearn.regression(g, optimizer='sgd', learning_rate=2.,\n",
    "                           loss='mean_square')\n",
    "\n",
    "    # Model training\n",
    "    m = tflearn.DNN(g)\n",
    "    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n",
    "\n",
    "    # Test model\n",
    "    print(\"Testing NOT operator\")\n",
    "    print(\"NOT 0:\", m.predict([[0.]]))\n",
    "    print(\"NOT 1:\", m.predict([[1.]]))\n",
    "\n",
    "# Logical OR operator\n",
    "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "Y = [[0.], [1.], [1.], [1.]]\n",
    "\n",
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    g = tflearn.input_data(shape=[None, 2])\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 1, activation='sigmoid')\n",
    "    g = tflearn.regression(g, optimizer='sgd', learning_rate=2.,\n",
    "                           loss='mean_square')\n",
    "\n",
    "    # Model training\n",
    "    m = tflearn.DNN(g)\n",
    "    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n",
    "\n",
    "    # Test model\n",
    "    print(\"Testing OR operator\")\n",
    "    print(\"0 or 0:\", m.predict([[0., 0.]]))\n",
    "    print(\"0 or 1:\", m.predict([[0., 1.]]))\n",
    "    print(\"1 or 0:\", m.predict([[1., 0.]]))\n",
    "    print(\"1 or 1:\", m.predict([[1., 1.]]))\n",
    "\n",
    "# Logical AND operator\n",
    "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "Y = [[0.], [0.], [0.], [1.]]\n",
    "\n",
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    g = tflearn.input_data(shape=[None, 2])\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 128, activation='linear')\n",
    "    g = tflearn.fully_connected(g, 1, activation='sigmoid')\n",
    "    g = tflearn.regression(g, optimizer='sgd', learning_rate=2.,\n",
    "                           loss='mean_square')\n",
    "\n",
    "    # Model training\n",
    "    m = tflearn.DNN(g)\n",
    "    m.fit(X, Y, n_epoch=100, snapshot_epoch=False)\n",
    "\n",
    "    # Test model\n",
    "    print(\"Testing AND operator\")\n",
    "    print(\"0 and 0:\", m.predict([[0., 0.]]))\n",
    "    print(\"0 and 1:\", m.predict([[0., 1.]]))\n",
    "    print(\"1 and 0:\", m.predict([[1., 0.]]))\n",
    "    print(\"1 and 1:\", m.predict([[1., 1.]]))\n",
    "\n",
    "'''\n",
    "Going further: Graph combination with multiple optimizers\n",
    "Create a XOR operator using product of NAND and OR operators\n",
    "'''\n",
    "# Data\n",
    "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "Y_nand = [[1.], [1.], [1.], [0.]]\n",
    "Y_or = [[0.], [1.], [1.], [1.]]\n",
    "\n",
    "# Graph definition\n",
    "with tf.Graph().as_default():\n",
    "    # Building a network with 2 optimizers\n",
    "    g = tflearn.input_data(shape=[None, 2])\n",
    "    # Nand operator definition\n",
    "    g_nand = tflearn.fully_connected(g, 32, activation='linear')\n",
    "    g_nand = tflearn.fully_connected(g_nand, 32, activation='linear')\n",
    "    g_nand = tflearn.fully_connected(g_nand, 1, activation='sigmoid')\n",
    "    g_nand = tflearn.regression(g_nand, optimizer='sgd',\n",
    "                                learning_rate=2.,\n",
    "                                loss='binary_crossentropy')\n",
    "    # Or operator definition\n",
    "    g_or = tflearn.fully_connected(g, 32, activation='linear')\n",
    "    g_or = tflearn.fully_connected(g_or, 32, activation='linear')\n",
    "    g_or = tflearn.fully_connected(g_or, 1, activation='sigmoid')\n",
    "    g_or = tflearn.regression(g_or, optimizer='sgd',\n",
    "                              learning_rate=2.,\n",
    "                              loss='binary_crossentropy')\n",
    "    # XOR merging Nand and Or operators\n",
    "    g_xor = tflearn.merge([g_nand, g_or], mode='elemwise_mul')\n",
    "\n",
    "    # Training\n",
    "    m = tflearn.DNN(g_xor)\n",
    "    m.fit(X, [Y_nand, Y_or], n_epoch=400, snapshot_epoch=False)\n",
    "\n",
    "    # Testing\n",
    "    print(\"Testing XOR operator\")\n",
    "    print(\"0 xor 0:\", m.predict([[0., 0.]]))\n",
    "    print(\"0 xor 1:\", m.predict([[0., 1.]]))\n",
    "    print(\"1 xor 0:\", m.predict([[1., 0.]]))\n",
    "    print(\"1 xor 1:\", m.predict([[1., 1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MNIST...\n",
      "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 001 Step: 000 Loss: 2.28758\n",
      "Epoch: 001 Step: 020 Loss: 1.62809\n",
      "Epoch: 001 Step: 040 Loss: 1.5921\n",
      "Epoch: 001 Step: 060 Loss: 1.535\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This tutorial will introduce how to combine TFLearn and Tensorflow, using\n",
    "TFLearn trainer with regular Tensorflow graph.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "# --------------------------------------\n",
    "# High-Level API: Using TFLearn wrappers\n",
    "# --------------------------------------\n",
    "\n",
    "# Using MNIST Dataset\n",
    "import tflearn.datasets.mnist as mnist\n",
    "mnist_data = mnist.read_data_sets(one_hot=True)\n",
    "\n",
    "# User defined placeholders\n",
    "with tf.Graph().as_default():\n",
    "    # Placeholders for data and labels\n",
    "    X = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=(None, 10), dtype=tf.float32)\n",
    "\n",
    "    net = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "    # Using TFLearn wrappers for network building\n",
    "    net = tflearn.conv_2d(net, 32, 3, activation='relu')\n",
    "    net = tflearn.max_pool_2d(net, 2)\n",
    "    net = tflearn.local_response_normalization(net)\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.conv_2d(net, 64, 3, activation='relu')\n",
    "    net = tflearn.max_pool_2d(net, 2)\n",
    "    net = tflearn.local_response_normalization(net)\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 128, activation='tanh')\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 256, activation='tanh')\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 10, activation='softmax')\n",
    "\n",
    "    # Defining other ops using Tensorflow\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net, Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        batch_size = 128\n",
    "        for epoch in range(2): # 2 epochs\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(mnist_data.train.num_examples/batch_size)\n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = mnist_data.train.next_batch(batch_size)\n",
    "                sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "                cost = sess.run(loss, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "                avg_cost += cost/total_batch\n",
    "                if i % 20 == 0:\n",
    "                    print(\"Epoch:\", '%03d' % (epoch+1), \"Step:\", '%03d' % i,\n",
    "                          \"Loss:\", str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tflearn\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name load_csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cf7b2300e331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load CSV File, indicate the first col. represents labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#data, labels = load_csv('train.csv', target_column=0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#                       categorical_labels = True, n_classes=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name load_csv"
     ]
    }
   ],
   "source": [
    "#TODO1: Why it doesnt work?\n",
    "# Download the Titanic dataset\n",
    "#from tflearn.datasets import titanic\n",
    "#titanic.download_dataset('titanic_dataset.csv')\n",
    "\n",
    "# Load CSV File, indicate the first col. represents labels.\n",
    "#from tflearn.data_utils import load_csv\n",
    "#data, labels = load_csv('train.csv', target_column=0,\n",
    "#                       categorical_labels = True, n_classes=2)\n",
    "\n",
    "\"\"\"\n",
    "import csv as csv\n",
    "\n",
    "csv_file_object = csv.reader(open('./train.csv', 'rb'))\n",
    "header = csv_file_object.next()\n",
    "\n",
    "data = []\n",
    "for row in csv_file_object:\n",
    "    data.append(row)\n",
    "data = np.array(data)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
