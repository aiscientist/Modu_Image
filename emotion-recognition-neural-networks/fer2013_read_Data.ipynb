{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import sys\n",
    "from constants import *\n",
    "from emotion_recognition import EmotionRecognition\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Building CNN\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.\n\t [[Node: Momentum_2/zeros_7 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [18432,3072] values: 0 0 0...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nCaused by op u'Momentum_2/zeros_7', defined at:\n  File \"/home/ryan/anaconda2/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ryan/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-21cd40d76733>\", line 2, in <module>\n    network.build_network()\n  File \"emotion_recognition.py\", line 42, in build_network\n    tensorboard_verbose = 2\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/models/dnn.py\", line 57, in __init__\n    session=session)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 111, in __init__\n    clip_gradients)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 574, in initialize_training_ops\n    name=\"apply_grad_op_\" + str(i))\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 300, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/momentum.py\", line 51, in _create_slots\n    self._zeros_slot(v, \"momentum\", self._name)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 494, in _zeros_slot\n    named_slots[var] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 106, in create_zeros_slot\n    val = array_ops.zeros(primary.get_shape().as_list(), dtype=dtype)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1131, in zeros\n    output = constant(0, shape=shape, dtype=dtype, name=name)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 167, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-21cd40d76733>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmotionRecognition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data_kike.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./labels_kike.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/git_ryan/Modu_Image/Modu_Image/emotion-recognition-neural-networks/emotion_recognition.pyc\u001b[0m in \u001b[0;36mbuild_network\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m       \u001b[0mcheckpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSAVE_DIRECTORY\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/emotion_recognition'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m       \u001b[0mmax_checkpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m       \u001b[0mtensorboard_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/models/dnn.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, network, clip_gradients, tensorboard_verbose, tensorboard_dir, checkpoint_path, max_checkpoints, session)\u001b[0m\n\u001b[0;32m     55\u001b[0m                                \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                                \u001b[0mmax_checkpoints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_checkpoints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                                session=session)\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/helpers/trainer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, train_ops, graph, clip_gradients, tensorboard_dir, tensorboard_verbose, checkpoint_path, max_checkpoints, keep_checkpoint_every_n_hours, random_seed, session)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestored\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     def fit(self, feed_dicts, n_epoch=10, val_feed_dicts=None, show_metric=False,\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 382\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    383\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 655\u001b[1;33m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 723\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: Momentum_2/zeros_7 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [18432,3072] values: 0 0 0...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nCaused by op u'Momentum_2/zeros_7', defined at:\n  File \"/home/ryan/anaconda2/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ryan/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-21cd40d76733>\", line 2, in <module>\n    network.build_network()\n  File \"emotion_recognition.py\", line 42, in build_network\n    tensorboard_verbose = 2\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/models/dnn.py\", line 57, in __init__\n    session=session)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 111, in __init__\n    clip_gradients)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 574, in initialize_training_ops\n    name=\"apply_grad_op_\" + str(i))\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 300, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/momentum.py\", line 51, in _create_slots\n    self._zeros_slot(v, \"momentum\", self._name)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 494, in _zeros_slot\n    named_slots[var] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 106, in create_zeros_slot\n    val = array_ops.zeros(primary.get_shape().as_list(), dtype=dtype)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1131, in zeros\n    output = constant(0, shape=shape, dtype=dtype, name=name)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 167, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "network = EmotionRecognition()\n",
    "network.build_network()\n",
    "\n",
    "images = np.load('./data_kike.npy')\n",
    "labels = np.load('./labels_kike.npy')\n",
    "\n",
    "#images = images.reshape([-1, SIZE_FACE, SIZE_FACE, 1])\n",
    "#labels = labels.reshape([-1, len(EMOTIONS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13975"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.zeros((len(EMOTIONS),len(EMOTIONS)))\n",
    "for i in xrange(images.shape[0]):\n",
    "    result = network.predict(images[i])\n",
    "    data[np.argmax(labels[i]), result[0].index(max(result[0]))] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.06584821  0.          0.93415179\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.04290429  0.          0.95709571\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.04761905  0.          0.95238095\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.03048327  0.          0.96951673\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.07432854  0.          0.92567146\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.03128689  0.          0.96871311\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.0678392   0.          0.9321608\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    total = np.sum(data[i])\n",
    "    for x in range(len(data[0])):\n",
    "        data[i][x] = data[i][x] / total\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Generating graph\n"
     ]
    }
   ],
   "source": [
    "print '[+] Generating graph'\n",
    "c = plt.pcolor(data, edgecolors = 'k', linewidths = 4, cmap = 'Blues', vmin = 0.0, vmax = 1.0)\n",
    "def show_values(pc, fmt=\"%.2f\", **kw):\n",
    "    from itertools import izip\n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.get_axes()\n",
    "    ax.set_yticks(np.arange(len(EMOTIONS)) + 0.5, minor = False)\n",
    "    ax.set_xticks(np.arange(len(EMOTIONS)) + 0.5, minor = False)\n",
    "    ax.set_xticklabels(EMOTIONS, minor = False)\n",
    "    ax.set_yticklabels(EMOTIONS, minor = False)\n",
    "    for p, color, value in izip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        ax.text(x, y, fmt % value, ha = \"center\", va = \"center\", color = color, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/anaconda2/lib/python2.7/site-packages/matplotlib/artist.py:221: MatplotlibDeprecationWarning: This has been deprecated in mpl 1.5, please use the\n",
      "axes property.  A removal date has not been set.\n",
      "  warnings.warn(_get_axes_msg, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "show_values(c)\n",
    "plt.xlabel('Predicted Emotion')\n",
    "plt.ylabel('Real Emotion')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
