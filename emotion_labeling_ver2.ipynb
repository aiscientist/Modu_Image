{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of this code\n",
    "\n",
    "http://www.paulvangent.com/2016/04/01/emotion-recognition-with-python-opencv-and-a-face-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Labeling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Define emotion order\n",
    "#participants = glob.glob(\"source_emotion/*\") #Returns a list of all folders with participant numbers\n",
    "\n",
    "emotion = 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SIZE_FACE = 64\n",
    "\n",
    "data = {}\n",
    "\n",
    "def get_files(emotion): #Define function to get file list, randomly shuffle it and split 80/20\n",
    "    files = glob.glob(\"dataset/%s/*\" %emotion)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)] #get first 80% of file list\n",
    "    prediction = files[-int(len(files)*0.2):] #get last 20% of file list\n",
    "    return training, prediction\n",
    "\n",
    "#img_preprocessing\n",
    "#http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "\n",
    "def make_sets():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "    for emotion in emotions:\n",
    "        training, prediction = get_files(emotion)\n",
    "        #Append data to training and prediction list, and generate labels 0-7\n",
    "        for item in training:\n",
    "            image = cv2.imread(item) #open image\n",
    "            img_blur = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "            gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "            img_norm = cv2.resize(gray, (SIZE_FACE, SIZE_FACE), interpolation = cv2.INTER_CUBIC) / 255. #normalization\n",
    "            training_data.append(img_norm) #append image array to training data list\n",
    "            training_labels.append(emotions.index(emotion))\n",
    "    \n",
    "        for item in prediction: #repeat above process for prediction set\n",
    "            image = cv2.imread(item)\n",
    "            img_blur = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "            gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "            img_norm = cv2.resize(gray, (SIZE_FACE, SIZE_FACE), interpolation = cv2.INTER_CUBIC) / 255. #normalization\n",
    "            prediction_data.append(img_norm)\n",
    "            prediction_labels.append(emotions.index(emotion))\n",
    "\n",
    "    return training_data, training_labels, prediction_data, prediction_labels\n",
    "\n",
    "training_data, training_labels, prediction_data, prediction_labels = make_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert all data into numpy\n",
    "X, Y, X_test, Y_test = np.array(training_data), np.array(training_labels), np.array(prediction_data), np.array(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = X[0]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Show image\n",
    "\n",
    "from scipy.misc import toimage\n",
    "toimage(a).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training with TF learn (alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "#import tflearn\n",
    "#from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "#from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling and one hot encoding\n",
    "\n",
    "X, Y = shuffle(X,Y)\n",
    "X_test, Y_test = shuffle(X_test, Y_test)\n",
    "#Y = to_categorical(Y, 8)\n",
    "#Y_test = to_categorical(Y_test, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Just for checking\n",
    "X = X[0:500, ]\n",
    "Y = Y[0:500, ]\n",
    "X_test = X[0:100, ]\n",
    "Y_test = Y[0:100, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data shuffle code\n",
    "\n",
    "#Shuffle the data\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "X, Y = randomize(X, Y)\n",
    "testX, testY = randomize(testX, testY)\n",
    "#test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "#valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=8):\n",
    "  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "  num_labels = labels_dense.shape[0]\n",
    "  index_offset = np.arange(num_labels) * num_classes\n",
    "  labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "  return labels_one_hot\n",
    "\n",
    "Y = dense_to_one_hot(Y)\n",
    "Y_test = dense_to_one_hot(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert dataset into...\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "X = X.reshape([-1, IMAGE_SIZE, IMAGE_SIZE, 1])\n",
    "X_test = X_test.reshape([-1, IMAGE_SIZE, IMAGE_SIZE, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m2.57031\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 020 | loss: 2.57031 - acc: 0.1294 | val_loss: 2.22483 - val_acc: 0.1700 -- iter: 500/500\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m2.57031\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 020 | loss: 2.57031 - acc: 0.1294 | val_loss: 2.22483 - val_acc: 0.1700 -- iter: 500/500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Building convolutional network\n",
    "network = input_data(shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name='input')\n",
    "network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 128, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "network = fully_connected(network, 256, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "network = fully_connected(network, 512, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "network = fully_connected(network, 8, activation='softmax')\n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.fit({'input': X}, {'target': Y}, n_epoch=20,\n",
    "           validation_set=({'input': X_test}, {'target': Y_test}),\n",
    "           snapshot_step=100, show_metric=True, run_id='convnet_mnist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
