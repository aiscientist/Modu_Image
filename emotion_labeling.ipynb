{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of this code\n",
    "\n",
    "http://www.paulvangent.com/2016/04/01/emotion-recognition-with-python-opencv-and-a-face-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Labeling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Define emotion order\n",
    "#participants = glob.glob(\"source_emotion/*\") #Returns a list of all folders with participant numbers\n",
    "\n",
    "emotion = 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "def get_files(emotion): #Define function to get file list, randomly shuffle it and split 80/20\n",
    "    files = glob.glob(\"dataset_test/%s/*\" %emotion)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)] #get first 80% of file list\n",
    "    prediction = files[-int(len(files)*0.2):] #get last 20% of file list\n",
    "    return training, prediction\n",
    "\n",
    "def make_sets():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "    for emotion in emotions:\n",
    "        training, prediction = get_files(emotion)\n",
    "        #Append data to training and prediction list, and generate labels 0-7\n",
    "        for item in training:\n",
    "            image = cv2.imread(item) #open image\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "            training_data.append(image) #append image array to training data list\n",
    "            training_labels.append(emotions.index(emotion))\n",
    "    \n",
    "        for item in prediction: #repeat above process for prediction set\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            prediction_data.append(image)\n",
    "            prediction_labels.append(emotions.index(emotion))\n",
    "\n",
    "    return training_data, training_labels, prediction_data, prediction_labels\n",
    "\n",
    "training_data, training_labels, prediction_data, prediction_labels = make_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 48, 48, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training with TF learn (alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "#import tflearn\n",
    "#from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "#from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert all data into numpy\n",
    "X, Y, X_test, Y_test = np.array(training_data), np.array(training_labels), np.array(prediction_data), np.array(prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data shuffle code\n",
    "\n",
    "#Shuffle the data\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "X, Y = randomize(X, Y)\n",
    "testX, testY = randomize(testX, testY)\n",
    "#test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "#valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shuffling and one hot encoding\n",
    "\n",
    "X, Y = shuffle(X,Y)\n",
    "\n",
    "#Y = to_categorical(Y, 8)\n",
    "#Y_test = to_categorical(Y_test, 8)\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes=8):\n",
    "  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "  num_labels = labels_dense.shape[0]\n",
    "  index_offset = np.arange(num_labels) * num_classes\n",
    "  labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "  return labels_one_hot\n",
    "\n",
    "Y = dense_to_one_hot(Y)\n",
    "Y_test = dense_to_one_hot(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(867, 48, 48, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert dataset into...\n",
    "IMAGE_SIZE = 48\n",
    "\n",
    "X = X.reshape([-1, IMAGE_SIZE, IMAGE_SIZE, 1])\n",
    "X_test = X_test.reshape([-1, IMAGE_SIZE, IMAGE_SIZE, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: convnet_mnist\n",
      "Log directory: /tmp/tflearn_logs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/data_flow.py\", line 183, in fill_feed_dict_queue\n",
      "    data = self.retrieve_data(batch_ids)\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/data_flow.py\", line 218, in retrieve_data\n",
      "    utils.slice_array(self.feed_dict[key], batch_ids)\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/utils.py\", line 166, in slice_array\n",
      "    return X[start]\n",
      "IndexError: index 8769 is out of bounds for axis 0 with size 3483\n",
      "\n",
      "Exception in thread Thread-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/data_flow.py\", line 183, in fill_feed_dict_queue\n",
      "    data = self.retrieve_data(batch_ids)\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/data_flow.py\", line 218, in retrieve_data\n",
      "    utils.slice_array(self.feed_dict[key], batch_ids)\n",
      "  File \"/home/ryan/anaconda2/lib/python2.7/site-packages/tflearn/utils.py\", line 166, in slice_array\n",
      "    return X[start]\n",
      "IndexError: index 8902 is out of bounds for axis 0 with size 3483\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Training samples: 20898\n",
      "Validation samples: 5202\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Building convolutional network\n",
    "network = input_data(shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name='input')\n",
    "network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "#network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n",
    "#network = max_pool_2d(network, 2)\n",
    "#network = local_response_normalization(network)\n",
    "#network = fully_connected(network, 128, activation='tanh')\n",
    "network = fully_connected(network, 64, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "#network = fully_connected(network, 256, activation='tanh')\n",
    "network = fully_connected(network, 128, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "network = fully_connected(network, 8, activation='softmax')\n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.fit({'input': X}, {'target': Y}, n_epoch=20,\n",
    "           validation_set=({'input': X_test}, {'target': Y_test}),\n",
    "           snapshot_step=100, show_metric=True, run_id='convnet_mnist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
