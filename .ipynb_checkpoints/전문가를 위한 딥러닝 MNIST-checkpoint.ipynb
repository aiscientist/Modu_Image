{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./samples/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./samples/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./samples/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./samples/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./samples/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소프트맥스 회귀 모델 만들기\n",
    "\n",
    "이 장에서 우리는 단일 선형 레이어로 된 소프트맥스 회귀 모델을 만들 것입니다. 다음 장에서, 우리는 이 모델을 다중 레이어 합성곱 네트워크로 된 소프트맥스 회귀로 확장할 것입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Placeholders: 입력 이미지와 목표 출력 클래스를 위한 노드를 만들어서 계산 그래프를 만들자\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "#Variables\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10])) #W는 784*10 행렬\n",
    "b = tf.Variable(tf.zeros([10])) #b는 10차원 백터\n",
    "\n",
    "sess.run(tf.initialize_all_variables())#항상 세션으로 사용하기 전에 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 클래스 및 비용 함수(Cost Function)\n",
    "\n",
    "이제 우리 회귀 모델을 만들 수 있습니다. 딱 한 줄만 필요합니다! 벡터화된 입력 이미지 x를 가중치 행렬 W로 곱하고, 편향(bias) b를 더한 다음 각 클래스에 지정된 소프트맥스 확률들을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "#훈련 과정에소 최소화 될 비용 함수들을 지정. 비용함수는 목표와 모델 예측간의\n",
    "#교차 엔트로피\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련시키기\n",
    "\n",
    "이제 모델과 훈련 비용 함수를 정의했으므로, TensorFlow를 사용하여 모델을 훈련하는 것은 간단합니다. TensorFlow는 전체 계산 그래프를 알고 있으므로, 각 변수들에 대하여 비용 그라디언트를 찾기 위해 자동 미분을 사용할 수 있습니다. TensorFlow에는 다양한 내장 최적화 알고리즘들 이 있습니다. 이 예제에서는 교차 엔트로피를 하강시키기 위해 가파른 그라디언트 하강법 (steepest gradient descent) 을 0.01의 보폭으로 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "#이 한 줄에서 TensorFlow가 진짜로 하는 일은 \n",
    "#계산 그래프에 새 작업을 추가하는 일입니다. \n",
    "#이러한 작업들에는 그라디언트를 계산하고, 매개 변수가 \n",
    "#갱신 보폭을 계산하고, 갱신된 보폭을 매개 변수에 반영하는 단계를 포함하고 있습니다.\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50) #50개 훈련 예제 불러오기\n",
    "    train_step.run(feed_dict = {x: batch[0], y_: batch[1]})\n",
    "\n",
    "#feed dict를 활용하면 계산 그래프 내의 어떠한 텐서도 대체 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가하기\n",
    "\n",
    "우리 모델이 얼마나 좋을까요?\n",
    "\n",
    "첫번째로 우리가 맞는 라벨을 예측했는지를 확인할 것입니다.. tf.argmax는 특정한 축을 따라 가장 큰 원소의 색인을 알려주는 엄청나게 유용한 함수입니다. 예를 들어 tf.argmax(y,1) 는 진짜 라벨이 tf.argmax(y_,1) 일때 우리 모델이 각 입력에 대하여 가장 정확하다고 생각하는 라벨입니다. 우리는 tf.equal 을 이용해 예측이 실제와 맞았는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "#결과는 부울 리스트를 주고 부정 소솟점으로 캐스팅한 후 평균값 구하기\n",
    "#예를 들어, [True, False, True, True]는 [1,0,1,1] 이 되고 평균값은 0.75\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 레이어 합성곱 네트워크\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 초기화\n",
    "\n",
    "이 모델을 만들기 위해서, 우리는 많은 가중치 및 편향을 만들 필요가 있습니다. 일반적으로 작은 크기의 노이즈로 가중치를 초기화해서 대칭성을 파괴하고, 그라디언트가 0이 되는 경우를 방지합니다. 우리가 ReLU 뉴런을 사용할 것이므로, 그것들을 약간 양수의 편향을 주어 초기화해서 \"죽은 뉴런\" 이 되는 것을 막는 것도 좋은 시도입니다. 모델을 만들 때 마다 이 과정을 반복하는 대신, 우리를 위해 이걸 해줄 편리한 두 함수를 만듭시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱과 풀링 (Pooling)\n",
    "\n",
    "TensorFlow는 또한 합성곱과 풀링 작업을 위한 많은 유연성을 제공합니다. 어떻게 경계를 다룰까요? 이동 (stride) 크기는 얼마인가요? 이 예시에서, 우리는 언제나 가장 기본적인 버전을 선택할 것입니다. 합성곱은 하나의 이동 크기를 사용하고, 0로 패딩되어 결과적으로 출력의 크기가 입력의 크기와 같게 됩니다. 풀링은 2x2 블럭의 평범한 max pooling 입니다. 코드를 깨끗하게 유지하기 위해 이러한 작업들을 함수로 추상화합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 합성곱 레이어\n",
    "\n",
    "이제 첫번째 레이어를 구현할 수 있습니다. 이 레이어는 합성곱과 max pooling 으로 구성될 것입니다. 합성곱은 5x5 조각 각각마다 32개의 특징을 계산할 것입니다. 가중치 텐서는 [5, 5, 1, 32] 형태가 될 것입니다. 앞의 2 차원은 패치 크기이며, 뒷부분은 출력 채널의 숫자입니다. 또한 각 출력 채널에 대하여 구성 요소 편향 벡터가 있을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "#레이어를 적용하기 위하여 우선 x를 4차원 텐서의 형태로 변환하는데, 두번째와 세번째 차원을 이미지의 폭과 높이에 해당하고, \n",
    "#마지막 차원은 색깔 채널의 수에 대응하는 차원입니다.\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "#그리고 x_image를 가중치 텐서와 합성곱하고, 편향을 더한 후, Relu함수를 적용 한 후, 마지막으로 max pool 합니다.\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두번째 합성곱 레이어\n",
    "\n",
    "심층 네트워크를 만들기 위해 이 유형의 여러 레이어를 쌓습니다. 두번째 레이어는 각각 5x5 조각으로 된 64개의 특징들을 갖고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Densely Connected Layer\n",
    "\n",
    "이제 이미지 크기는 7x7로 줄어 들었습니다. 전체 이미지를 처리할 수 있도록 1024개 뉴런이 있는 전부 연결된 레이어를 추가합니다. 풀링 레이어로부터의 텐서를 벡터들의 배치로 형태를 바꾸고, 가중치 행렬을 곱하고, 편향을 더하고, ReLU를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "탈락 (Dropout)\n",
    "\n",
    "오버피팅을 줄이기 위해 우리는 판독 레이어 전에 탈락을 적용합니다. 뉴런의 출력이 탈락 동안 유지될 확률에 대한 placeholder를 만듭니다. 이건 훈련 도중에는 탈락을 설정하고 테스트 기간동안에는 해제할 수 있게 해 줍니다. TensorFlow의 tf.nn.dropout 작업은 자동으로 뉴런 출력에 마스킹을 할 뿐 아니라 스케일을 조정해 주므로, 탈락은 어떠한 추가적인 스케일링 없이 동작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "판독 레이어\n",
    "\n",
    "마지막으로, 위에서 소프트맥스 회귀에서 사용했던것과 같은 소프트맥스 레이어를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련 및 평가\n",
    "\n",
    "이 모델이 얼마나 좋을까요? 훈련 및 평가를 하기 위해 간단한 단일 레이어 소프트맥스 네트워크에서 사용한것과 거의 같은 코드를 사용할 것입니다. 차이점은 다음과 같습니다: 가파른 그라디언트 하강 최적화 모듈을 더 세련된 ADAM 최적화 모듈로 교체할 것이고, keep_prob 인수를 feed_dict에 포함하여 낙오율을 조정할 것입니다. 그리고 훈련 과정중 100번의 반복마다 기록 (logging)을 추가할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./samples/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./samples/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./samples/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./samples/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7fcc5807be50>> ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.8\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.88\n",
      "step 400, training accuracy 1\n",
      "step 500, training accuracy 0.94\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 0.9\n",
      "step 800, training accuracy 0.9\n",
      "step 900, training accuracy 0.98\n",
      "step 1000, training accuracy 0.98\n",
      "step 1100, training accuracy 0.98\n",
      "step 1200, training accuracy 0.96\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 1\n",
      "step 1600, training accuracy 0.98\n",
      "step 1700, training accuracy 0.98\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 1\n",
      "step 2000, training accuracy 1\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 0.98\n",
      "step 2300, training accuracy 0.98\n",
      "step 2400, training accuracy 0.96\n",
      "step 2500, training accuracy 1\n",
      "step 2600, training accuracy 0.98\n",
      "step 2700, training accuracy 0.98\n",
      "step 2800, training accuracy 0.98\n",
      "step 2900, training accuracy 0.98\n",
      "step 3000, training accuracy 0.98\n",
      "step 3100, training accuracy 1\n",
      "step 3200, training accuracy 0.98\n",
      "step 3300, training accuracy 0.98\n",
      "step 3400, training accuracy 0.98\n",
      "step 3500, training accuracy 1\n",
      "step 3600, training accuracy 1\n",
      "step 3700, training accuracy 0.98\n",
      "step 3800, training accuracy 1\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 1\n",
      "step 4100, training accuracy 1\n",
      "step 4200, training accuracy 1\n",
      "step 4300, training accuracy 1\n",
      "step 4400, training accuracy 1\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 0.98\n",
      "step 4700, training accuracy 1\n",
      "step 4800, training accuracy 1\n",
      "step 4900, training accuracy 1\n",
      "step 5000, training accuracy 1\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 1\n",
      "step 5300, training accuracy 0.98\n",
      "step 5400, training accuracy 0.98\n",
      "step 5500, training accuracy 1\n",
      "step 5600, training accuracy 1\n",
      "step 5700, training accuracy 1\n",
      "step 5800, training accuracy 1\n",
      "step 5900, training accuracy 0.96\n",
      "step 6000, training accuracy 1\n",
      "step 6100, training accuracy 1\n",
      "step 6200, training accuracy 0.98\n",
      "step 6300, training accuracy 1\n",
      "step 6400, training accuracy 1\n",
      "step 6500, training accuracy 0.98\n",
      "step 6600, training accuracy 0.98\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 0.98\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 0.98\n",
      "step 7300, training accuracy 0.94\n",
      "step 7400, training accuracy 1\n",
      "step 7500, training accuracy 0.98\n",
      "step 7600, training accuracy 1\n",
      "step 7700, training accuracy 1\n",
      "step 7800, training accuracy 1\n",
      "step 7900, training accuracy 1\n",
      "step 8000, training accuracy 0.98\n",
      "step 8100, training accuracy 0.98\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 0.96\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 1\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 0.98\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 1\n",
      "step 9500, training accuracy 1\n",
      "step 9600, training accuracy 1\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 0.96\n",
      "step 9900, training accuracy 1\n",
      "step 10000, training accuracy 1\n",
      "step 10100, training accuracy 1\n",
      "step 10200, training accuracy 0.98\n",
      "step 10300, training accuracy 1\n",
      "step 10400, training accuracy 0.98\n",
      "step 10500, training accuracy 1\n",
      "step 10600, training accuracy 1\n",
      "step 10700, training accuracy 0.98\n",
      "step 10800, training accuracy 0.98\n",
      "step 10900, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 11100, training accuracy 1\n",
      "step 11200, training accuracy 1\n",
      "step 11300, training accuracy 1\n",
      "step 11400, training accuracy 1\n",
      "step 11500, training accuracy 1\n",
      "step 11600, training accuracy 1\n",
      "step 11700, training accuracy 1\n",
      "step 11800, training accuracy 0.98\n",
      "step 11900, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 12100, training accuracy 1\n",
      "step 12200, training accuracy 1\n",
      "step 12300, training accuracy 1\n",
      "step 12400, training accuracy 1\n",
      "step 12500, training accuracy 1\n",
      "step 12600, training accuracy 0.98\n",
      "step 12700, training accuracy 0.98\n",
      "step 12800, training accuracy 1\n",
      "step 12900, training accuracy 1\n",
      "step 13000, training accuracy 1\n",
      "step 13100, training accuracy 1\n",
      "step 13200, training accuracy 1\n",
      "step 13300, training accuracy 1\n",
      "step 13400, training accuracy 1\n",
      "step 13500, training accuracy 1\n",
      "step 13600, training accuracy 1\n",
      "step 13700, training accuracy 1\n",
      "step 13800, training accuracy 1\n",
      "step 13900, training accuracy 1\n",
      "step 14000, training accuracy 0.98\n",
      "step 14100, training accuracy 1\n",
      "step 14200, training accuracy 1\n",
      "step 14300, training accuracy 1\n",
      "step 14400, training accuracy 1\n",
      "step 14500, training accuracy 1\n",
      "step 14600, training accuracy 1\n",
      "step 14700, training accuracy 1\n",
      "step 14800, training accuracy 1\n",
      "step 14900, training accuracy 1\n",
      "step 15000, training accuracy 1\n",
      "step 15100, training accuracy 1\n",
      "step 15200, training accuracy 1\n",
      "step 15300, training accuracy 1\n",
      "step 15400, training accuracy 1\n",
      "step 15500, training accuracy 1\n",
      "step 15600, training accuracy 1\n",
      "step 15700, training accuracy 1\n",
      "step 15800, training accuracy 1\n",
      "step 15900, training accuracy 1\n",
      "step 16000, training accuracy 0.98\n",
      "step 16100, training accuracy 1\n",
      "step 16200, training accuracy 1\n",
      "step 16300, training accuracy 1\n",
      "step 16400, training accuracy 1\n",
      "step 16500, training accuracy 1\n",
      "step 16600, training accuracy 0.98\n",
      "step 16700, training accuracy 1\n",
      "step 16800, training accuracy 1\n",
      "step 16900, training accuracy 1\n",
      "step 17000, training accuracy 1\n",
      "step 17100, training accuracy 1\n",
      "step 17200, training accuracy 1\n",
      "step 17300, training accuracy 1\n",
      "step 17400, training accuracy 1\n",
      "step 17500, training accuracy 1\n",
      "step 17600, training accuracy 1\n",
      "step 17700, training accuracy 1\n",
      "step 17800, training accuracy 1\n",
      "step 17900, training accuracy 1\n",
      "step 18000, training accuracy 1\n",
      "step 18100, training accuracy 1\n",
      "step 18200, training accuracy 1\n",
      "step 18300, training accuracy 1\n",
      "step 18400, training accuracy 1\n",
      "step 18500, training accuracy 1\n",
      "step 18600, training accuracy 1\n",
      "step 18700, training accuracy 1\n",
      "step 18800, training accuracy 1\n",
      "step 18900, training accuracy 1\n",
      "step 19000, training accuracy 0.98\n",
      "step 19100, training accuracy 1\n",
      "step 19200, training accuracy 1\n",
      "step 19300, training accuracy 1\n",
      "step 19400, training accuracy 1\n",
      "step 19500, training accuracy 1\n",
      "step 19600, training accuracy 1\n",
      "step 19700, training accuracy 1\n",
      "step 19800, training accuracy 1\n",
      "step 19900, training accuracy 1\n",
      "test accuracy 0.9929\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./samples/MNIST_data', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Densely Connected Layer\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# Train and Evaluate the Model\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
